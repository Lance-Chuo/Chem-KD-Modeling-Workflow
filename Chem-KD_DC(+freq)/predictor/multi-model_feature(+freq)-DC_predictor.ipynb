{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301bdf5-6ff3-477b-9af3-65b7baf03177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, global_dim, hidden_dims, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.node_norm = torch.nn.BatchNorm1d(node_dim)\n",
    "        if edge_dim:\n",
    "            self.edge_norm = torch.nn.BatchNorm1d(edge_dim)\n",
    "        if global_dim:\n",
    "            self.global_norm = torch.nn.BatchNorm1d(global_dim)\n",
    "            self.global_mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(global_dim, hidden_dims[-1]),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Dropout(dropout)\n",
    "            )\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        in_dim = node_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            self.convs.append(GCNConv(in_dim, h_dim))\n",
    "            in_dim = h_dim\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.final_dim = hidden_dims[-1] * (2 if global_dim else 1)\n",
    "        self.output_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.final_dim, self.final_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(self.final_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, return_feat=False):\n",
    "        x = self.node_norm(data.x)\n",
    "        if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n",
    "            _ = self.edge_norm(data.edge_attr)\n",
    "        u = data.u if hasattr(data, 'u') else None\n",
    "        if u is not None:\n",
    "            u = self.global_norm(u)\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            x = torch.nn.functional.relu(conv(x, data.edge_index))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        node_pool = global_mean_pool(x, data.batch)\n",
    "        h = torch.cat([node_pool, self.global_mlp(u)], dim=1) if u is not None else node_pool\n",
    "        out = self.output_mlp(h).squeeze(-1)\n",
    "        return (out, h) if return_feat else out\n",
    "\n",
    "def get_model_hash(model):\n",
    "    params = []\n",
    "    for k, v in model.state_dict().items():\n",
    "        if \"num_batches_tracked\" in k:\n",
    "            continue\n",
    "        params.append(v.detach().cpu().float().view(-1))\n",
    "    params = torch.cat(params).numpy()\n",
    "    return hashlib.md5(params.tobytes()).hexdigest()\n",
    "\n",
    "def create_loader(graph_data, batch_size=32):\n",
    "    data_list = []\n",
    "    for graph in graph_data:\n",
    "        x = graph['x'].float()\n",
    "        edge_index = graph['edge_index'].long()\n",
    "        \n",
    "        edge_attr = graph.get('edge_attr', None)\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = edge_attr.float()\n",
    "        u = graph.get('u', None)\n",
    "        if u is not None:\n",
    "            u = u.float()\n",
    "        \n",
    "        data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, u=u))\n",
    "    return DataLoader(data_list, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "def predict_single_model(model_path, data_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_name = os.path.basename(model_path).replace('.pt', '')\n",
    "    print(f\"===== Processing Model: {model_name} =====\")\n",
    "    print(f\"Using Device: {device}\")\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    batch_size = checkpoint.get('batch_size', 64)\n",
    "    print(f\"Using Batch Size: {batch_size}\")\n",
    "    \n",
    "    print(f\"Checkpoint Keys: {list(checkpoint.keys())}\")\n",
    "\n",
    "    model = SimpleGNN(\n",
    "        node_dim=checkpoint['node_dim'],\n",
    "        edge_dim=checkpoint['edge_dim'],\n",
    "        global_dim=checkpoint['global_dim'],\n",
    "        hidden_dims=checkpoint['hidden_dims'],\n",
    "        dropout=checkpoint['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    if 'student_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['student_state_dict'], strict=True)\n",
    "    elif 'state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    else:\n",
    "        for key in checkpoint.keys():\n",
    "            if 'state' in key.lower() and isinstance(checkpoint[key], dict):\n",
    "                model.load_state_dict(checkpoint[key], strict=True)\n",
    "                print(f\"Loaded model parameters using key: '{key}'\")\n",
    "                break\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    current_hash = get_model_hash(model)\n",
    "    param_hash_key = 'student_param_hash' if 'student_param_hash' in checkpoint else 'param_hash' if 'param_hash' in checkpoint else None\n",
    "    if param_hash_key and param_hash_key in checkpoint:\n",
    "        print(f\"✅ Model Parameter Hash: {current_hash[:8]}... (Compared with training hash {checkpoint[param_hash_key][:8]}...)\")\n",
    "    else:\n",
    "        print(f\"✅ Model Parameter Hash: {current_hash[:8]}...\")\n",
    "\n",
    "    data_path = os.path.join(data_dir, \"graph_data.pt\")\n",
    "    assert os.path.exists(data_path), f\"Feature data not found: {data_path}\"\n",
    "    graph_data = torch.load(data_path, map_location='cpu')\n",
    "    print(f\"Loaded data from {data_dir}, total {len(graph_data)} samples\")\n",
    "\n",
    "    data_loader = create_loader(graph_data, batch_size=batch_size)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "            batch = batch.to(device)\n",
    "            pred_norm = model(batch)\n",
    "            all_preds.append(pred_norm.cpu().numpy())\n",
    "\n",
    "    preds_norm = np.concatenate(all_preds)\n",
    "    y_mean, y_std = checkpoint['y_mean'], checkpoint['y_std']\n",
    "    preds_raw = preds_norm * y_std + y_mean\n",
    "    print(f\"✅ Prediction Completed! Generated {len(preds_raw)} prediction values\\n\")\n",
    "\n",
    "    smiles_list = [graph['smiles'] for graph in graph_data]\n",
    "    \n",
    "    return model_name, preds_raw, smiles_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input/Output Path Configuration (modify according to actual needs)\n",
    "    model_dir = \"PATH/TO/MODEL_DIRECTORY\"\n",
    "    data_dir = \"PATH/TO/DATA_DIRECTORY\"\n",
    "    output_dir = \"PATH/TO/OUTPUT_DIRECTORY\"\n",
    "    \n",
    "    model_paths = [os.path.join(model_dir, f) for f in os.listdir(model_dir) if f.endswith('.pt')]\n",
    "    print(f\"Found {len(model_paths)} model files, prediction results will be saved to: {output_dir}\\n\")\n",
    "\n",
    "    all_predictions = {}\n",
    "    smiles_list = None\n",
    "\n",
    "    for i, model_path in enumerate(model_paths, 1):\n",
    "        try:\n",
    "            model_name, preds_raw, slist = predict_single_model(model_path, data_dir)\n",
    "            all_predictions[model_name] = preds_raw\n",
    "            if smiles_list is None:\n",
    "                smiles_list = slist\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing model {os.path.basename(model_path)}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print()\n",
    "        \n",
    "        if i < len(model_paths):\n",
    "            print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    if smiles_list is not None and all_predictions:\n",
    "        pred_df = pd.DataFrame({\n",
    "            'Sample_Index': np.arange(len(smiles_list)),\n",
    "            'SMILES': smiles_list\n",
    "        })\n",
    "        for model_name, preds in all_predictions.items():\n",
    "            pred_df[model_name] = preds\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        save_path = os.path.join(output_dir, \"all_model_predictions_summary_base_P-SMILES_rev(freq3+)_ultra_high_temp_PI_multi_freq_permittivity_20_feat.csv\")\n",
    "        pred_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✅ All model prediction results have been summarized and saved to: {save_path}\")\n",
    "    else:\n",
    "        print(\"❌ No valid prediction results obtained, cannot generate summary file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_gpu (GPU)",
   "language": "python",
   "name": "gnn_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
