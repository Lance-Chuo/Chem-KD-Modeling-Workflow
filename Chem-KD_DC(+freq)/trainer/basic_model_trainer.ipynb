{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f389f38-bf3c-411a-b5e2-2009babd3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, GCNConv\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "def get_model_hash(model):\n",
    "    params = []\n",
    "    for k, v in model.state_dict().items():\n",
    "        if \"num_batches_tracked\" in k:\n",
    "            continue\n",
    "        params.append(v.detach().cpu().float().view(-1))\n",
    "    params = torch.cat(params).numpy()\n",
    "    return hashlib.md5(params.tobytes()).hexdigest()\n",
    "\n",
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, global_dim, hidden_dims, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.node_norm = nn.BatchNorm1d(node_dim)\n",
    "        if edge_dim:\n",
    "            self.edge_norm = nn.BatchNorm1d(edge_dim)\n",
    "        if global_dim:\n",
    "            self.global_norm = nn.BatchNorm1d(global_dim)\n",
    "            self.global_mlp = nn.Sequential(\n",
    "                nn.Linear(global_dim, hidden_dims[-1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        self.convs = nn.ModuleList()\n",
    "        in_dim = node_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            self.convs.append(GCNConv(in_dim, h_dim))\n",
    "            in_dim = h_dim\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.final_dim = hidden_dims[-1] * (2 if global_dim else 1)\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(self.final_dim, self.final_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.final_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, return_feat=False):\n",
    "        x = self.node_norm(data.x)\n",
    "        if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n",
    "            _ = self.edge_norm(data.edge_attr)\n",
    "        u = data.u if hasattr(data, 'u') else None\n",
    "        if u is not None:\n",
    "            u = self.global_norm(u)\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, data.edge_index))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        node_pool = global_mean_pool(x, data.batch)\n",
    "        h = torch.cat([node_pool, self.global_mlp(u)], dim=1) if u is not None else node_pool\n",
    "        out = self.output_mlp(h).squeeze()\n",
    "        return (out, h) if return_feat else out\n",
    "\n",
    "def create_data_loader(graph_data, batch_size=32, shuffle=True, seed=42):\n",
    "    data_list = []\n",
    "    for graph in graph_data:\n",
    "        x = graph['x'].float()\n",
    "        edge_index = graph['edge_index'].long()\n",
    "        edge_attr = graph.get('edge_attr', None)\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = edge_attr.float()\n",
    "        u = graph.get('u', None)\n",
    "        if u is not None:\n",
    "            u = u.float()\n",
    "        y = graph['y'].float().view(-1)\n",
    "        \n",
    "        data_list.append(Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            u=u,\n",
    "            y=y\n",
    "        ))\n",
    "    \n",
    "    if shuffle:\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "        return DataLoader(\n",
    "            data_list,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            generator=generator,\n",
    "            num_workers=0\n",
    "        )\n",
    "    else:\n",
    "        return DataLoader(data_list, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "def train_model(\n",
    "    train_data_dir: str,\n",
    "    val_data_dir: str,\n",
    "    save_path: str,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    min_lr=1e-6,\n",
    "    hidden_dims=[64, 64],\n",
    "    dropout=0.2,\n",
    "    lr_patience=10,\n",
    "    es_patience=100,\n",
    "    seed=42,\n",
    "    no_save_epochs=200\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âš ï¸  No optimal R2 calculation and model saving for the first {no_save_epochs} epochs | Early stopping if no improvement for {es_patience} consecutive epochs\")\n",
    "\n",
    "    train_graph_data = torch.load(os.path.join(train_data_dir, \"graph_data.pt\"), map_location='cpu')\n",
    "    val_graph_data = torch.load(os.path.join(val_data_dir, \"graph_data.pt\"), map_location='cpu')\n",
    "\n",
    "    train_y = torch.stack([g['y'] for g in train_graph_data]).view(-1).float()\n",
    "    y_mean, y_std = train_y.mean().item(), train_y.std().item() + 1e-8\n",
    "    for g in train_graph_data + val_graph_data:\n",
    "        g['y'] = (g['y'] - y_mean) / y_std\n",
    "\n",
    "    train_loader = create_data_loader(train_graph_data, batch_size, True, seed=seed)\n",
    "    val_loader = create_data_loader(val_graph_data, batch_size, False, seed=seed)\n",
    "    val_batch = next(iter(val_loader)) if len(val_loader) > 0 else None\n",
    "\n",
    "    sample = train_graph_data[0]\n",
    "    node_dim = sample['x'].size(1)\n",
    "    edge_dim = sample.get('edge_attr').size(1) if sample.get('edge_attr') is not None else 0\n",
    "    global_dim = sample.get('u').size(1) if sample.get('u') is not None else 0\n",
    "\n",
    "    model = SimpleGCN(node_dim, edge_dim, global_dim, hidden_dims, dropout).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=lr_patience, min_lr=min_lr\n",
    "    )\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_r2': [], 'val_r2': []}\n",
    "    best_val_r2 = -float('inf')\n",
    "    patience = 0\n",
    "    r2_effective_thresh = 0.005\n",
    "    best_r2_rel_thresh = 0.005\n",
    "\n",
    "    print(f\"\\nðŸš€ Start training (total {epochs} epochs, seed={seed}) ===\")\n",
    "    print(f\"R2 effective improvement standard: absolute improvement â‰¥{r2_effective_thresh} or relative improvement â‰¥{best_r2_rel_thresh*100}% of the best R2\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            pred, _ = model(batch, return_feat=True)\n",
    "            loss = F.mse_loss(pred, batch.y.view(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        def eval_r2_loss(loader):\n",
    "            ys, preds, total_loss = [], [], 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch in loader:\n",
    "                    batch = batch.to(device, non_blocking=True)\n",
    "                    out = model(batch)\n",
    "                    loss = F.mse_loss(out, batch.y.view(-1))\n",
    "                    total_loss += loss.item() * batch.num_graphs\n",
    "                    ys.append(batch.y.view(-1).cpu().numpy())\n",
    "                    preds.append(out.cpu().numpy())\n",
    "            avg_loss = total_loss / len(loader.dataset)\n",
    "            r2 = r2_score(np.concatenate(ys), np.concatenate(preds))\n",
    "            return r2, avg_loss\n",
    "\n",
    "        train_r2, train_avg_loss = eval_r2_loss(train_loader)\n",
    "        val_r2, val_avg_loss = eval_r2_loss(val_loader)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        history['train_loss'].append(train_avg_loss)\n",
    "        history['val_loss'].append(val_avg_loss)\n",
    "        history['train_r2'].append(train_r2)\n",
    "        history['val_r2'].append(val_r2)\n",
    "\n",
    "        r2_effective = False\n",
    "        log_msg = \"\"\n",
    "        current_val_r2 = val_r2\n",
    "\n",
    "        if epoch <= no_save_epochs:\n",
    "            log_msg = f\"[First {no_save_epochs} epochs] Epoch {epoch:3d} | Train R2: {train_r2:.4f} | Val R2: {current_val_r2:.4f} (not for optimal calculation)\"\n",
    "        else:\n",
    "            rel_r2_thresh = max(r2_effective_thresh, best_val_r2 * best_r2_rel_thresh)\n",
    "            \n",
    "            if current_val_r2 > best_val_r2:\n",
    "                r2_delta = current_val_r2 - best_val_r2\n",
    "                if r2_delta >= r2_effective_thresh or r2_delta >= rel_r2_thresh:\n",
    "                    r2_effective = True\n",
    "                    best_val_r2 = current_val_r2\n",
    "                    \n",
    "                    current_hash = get_model_hash(model)\n",
    "                    with torch.no_grad():\n",
    "                        fixed_output = model(val_batch.to(device)).cpu().numpy() if val_batch is not None else None\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'y_mean': y_mean,\n",
    "                        'y_std': y_std,\n",
    "                        'node_dim': node_dim,\n",
    "                        'edge_dim': edge_dim,\n",
    "                        'global_dim': global_dim,\n",
    "                        'hidden_dims': hidden_dims,\n",
    "                        'dropout': dropout,\n",
    "                        'best_val_r2': best_val_r2,\n",
    "                        'best_train_r2': train_r2,\n",
    "                        'param_hash': current_hash,\n",
    "                        'fixed_output': fixed_output,\n",
    "                        'seed': seed,\n",
    "                        'saved_epoch': epoch\n",
    "                    }, save_path)\n",
    "                    log_msg = (f\"[Effective improvement] Epoch {epoch:3d} | \"\n",
    "                               f\"Train R2: {train_r2:.4f} | Val R2 updated to {best_val_r2:.4f} (improvement {r2_delta:.4f}) | \"\n",
    "                               f\"Hash={current_hash[:8]}... | Model saved\")\n",
    "                else:\n",
    "                    log_msg = (f\"[Minor improvement] Epoch {epoch:3d} | \"\n",
    "                               f\"Train R2: {train_r2:.4f} | Val R2={current_val_r2:.4f} (improvement {r2_delta:.4f} < threshold) | \"\n",
    "                               f\"Current best Val R2={best_val_r2:.4f}\")\n",
    "            else:\n",
    "                log_msg = (f\"[No improvement] Epoch {epoch:3d} | \"\n",
    "                           f\"Train R2: {train_r2:.4f} | Val R2={current_val_r2:.4f} | \"\n",
    "                           f\"Current best Val R2={best_val_r2:.4f}\")\n",
    "\n",
    "        if epoch > no_save_epochs:\n",
    "            if r2_effective:\n",
    "                patience = 0\n",
    "                print(log_msg)\n",
    "            else:\n",
    "                patience += 1\n",
    "                patience_checks = [es_patience//4, es_patience//2, int(es_patience*0.75), es_patience]\n",
    "                if patience % 10 == 0 or patience in patience_checks:\n",
    "                    print(f\"[Early stopping counter] Epoch {epoch:3d} | No effective improvement for {patience}/{es_patience} epochs | \"\n",
    "                          f\"Train R2: {train_r2:.4f} | Current Val R2={current_val_r2:.4f} | Best Val R2={best_val_r2:.4f}\")\n",
    "        else:\n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                print(log_msg)\n",
    "\n",
    "        if epoch == no_save_epochs:\n",
    "            print(f\"\\n[Stage switch] Epoch {epoch:3d} | First {no_save_epochs} epochs ended, start optimal R2 calculation and model saving\")\n",
    "\n",
    "        if epoch > no_save_epochs and patience >= es_patience:\n",
    "            print(f\"\\nðŸ›‘ [Early stopping triggered] Epoch {epoch:3d} | No effective R2 improvement for {es_patience} consecutive epochs | \"\n",
    "                  f\"Best Val R2={best_val_r2:.4f} | Corresponding Train R2={history['train_r2'][epoch - patience - 1]:.4f}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_r2'], label='Train R2', color='blue')\n",
    "    plt.plot(history['val_r2'], label='Val R2', color='orange')\n",
    "    plt.axhline(y=best_val_r2, color='red', linestyle='--', label=f'Best Val R2 ({best_val_r2:.4f})')\n",
    "    plt.axvline(x=no_save_epochs, color='gray', linestyle=':', label=f\"Optimal calculation start ({no_save_epochs})\")\n",
    "    if epoch > no_save_epochs:\n",
    "        best_epoch = epoch - patience\n",
    "        plt.axvline(x=best_epoch, color='green', linestyle='-.', label=f'Best R2 epoch ({best_epoch})')\n",
    "        plt.scatter(best_epoch, best_val_r2, color='red', s=100, zorder=5)\n",
    "    plt.title('Training & Validation R2')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('R2 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Val Loss', color='orange')\n",
    "    plt.axvline(x=no_save_epochs, color='gray', linestyle=':', label=f\"Optimal calculation start ({no_save_epochs})\")\n",
    "    plt.title('Training & Validation Loss (For reference only)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path.replace('.pt', '_curves.png'))\n",
    "    plt.close()\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        saved_info = torch.load(save_path)\n",
    "        print(f\"\\nðŸŽ¯ Training completed! Best Val R2: {best_val_r2:.4f} (Corresponding Train R2: {saved_info['best_train_r2']:.4f}), \"\n",
    "              f\"Model saved at {save_path} (Saved epoch: {saved_info['saved_epoch']})\")\n",
    "    else:\n",
    "        print(f\"\\nðŸŽ¯ Training completed! No model saved (Early stopped at epoch {epoch}, not exceeding {no_save_epochs} epochs or no effective improvement)\")\n",
    "\n",
    "    return best_val_r2, save_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory of training graph data\n",
    "    train_data_dir = \"TRAIN_DATA_DIR_PATH\"\n",
    "    # Directory of validation graph data\n",
    "    val_data_dir = \"VAL_DATA_DIR_PATH\"\n",
    "    # Directory to save trained models\n",
    "    save_dir = \"MODEL_SAVE_DIR_PATH\"\n",
    "\n",
    "    seeds = [0, 42, 100, 2025]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    all_results = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n===== Current random seed: {seed} =====\")\n",
    "        set_seed(seed)\n",
    "        out_path = os.path.join(save_dir, f\"gcn_best_seed({seed})_128_128_0.1.pt\")\n",
    "        best_val_r2, _ = train_model(\n",
    "            train_data_dir=train_data_dir,\n",
    "            val_data_dir=val_data_dir,\n",
    "            save_path=out_path,\n",
    "            epochs=1500,\n",
    "            batch_size=32,\n",
    "            lr=1e-3,\n",
    "            min_lr=1e-4,\n",
    "            hidden_dims=[128, 128],\n",
    "            dropout=0.1,\n",
    "            lr_patience=20,\n",
    "            es_patience=100,\n",
    "            seed=seed,\n",
    "            no_save_epochs=200\n",
    "        )\n",
    "        if os.path.exists(out_path):\n",
    "            best_train_r2 = torch.load(out_path)['best_train_r2']\n",
    "        else:\n",
    "            best_train_r2 = -float('inf')\n",
    "        all_results.append((seed, best_val_r2, best_train_r2))\n",
    "        print(f\"Seed {seed} â†’ Best Val R2: {best_val_r2:.4f} | Corresponding Train R2: {best_train_r2:.4f}\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\n===== Multi-seed training results summary =====\")\n",
    "    print(f\"{'Seed':<6} | {'Best Val R2':<12} | {'Corresponding Train R2':<12}\")\n",
    "    print(\"-\" * 40)\n",
    "    for s, val_r2, train_r2 in all_results:\n",
    "        print(f\"{s:<6} | {val_r2:.4f}        | {train_r2:.4f}\")\n",
    "    val_r2s = [r[1] for r in all_results]\n",
    "    train_r2s = [r[2] for r in all_results if r[2] != -float('inf')]\n",
    "    print(f\"\\nAverage Val R2 = {np.mean(val_r2s):.4f} Â± {np.std(val_r2s):.4f}\")\n",
    "    if train_r2s:\n",
    "        print(f\"Average Train R2 = {np.mean(train_r2s):.4f} Â± {np.std(train_r2s):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_gpu (GPU)",
   "language": "python",
   "name": "gnn_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
